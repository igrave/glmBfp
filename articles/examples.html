<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Using `glmBfp`: a binary regression example • glmBfp</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Using `glmBfp`: a binary regression example">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">glmBfp</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0-61</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/Cox.html">Using `glmBfp`: Cox models with test-based Bayes Factors</a></li>
    <li><a class="dropdown-item" href="../articles/examples.html">Using `glmBfp`: a binary regression example</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Using `glmBfp`: a binary regression example</h1>
                        <h4 data-toc-skip class="author">Daniel Sabanés
Bové</h4>
            
      

      <div class="d-none name"><code>examples.Rmd</code></div>
    </div>

    
    
<p>This short vignette shall introduce into the usage of the package
<code>glmBfp</code>. For more information on the methodology, see <span class="citation">Sabanés Bové and Held (2011)</span>. There you can also
find the references for the other tools mentioned here.</p>
<div class="section level2">
<h2 id="pima-indians-diabetes-data">Pima Indians diabetes data<a class="anchor" aria-label="anchor" href="#pima-indians-diabetes-data"></a>
</h2>
<p>We will have a look at the Pima Indians diabetes data, which is
available in the package <code>MASS</code>:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/" class="external-link">MASS</a></span><span class="op">)</span></span>
<span><span class="va">pima</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">Pima.tr</span>, <span class="va">Pima.te</span><span class="op">)</span></span>
<span><span class="va">pima</span><span class="op">$</span><span class="va">hasDiabetes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">pima</span><span class="op">$</span><span class="va">type</span> <span class="op">==</span> <span class="st">"Yes"</span><span class="op">)</span></span>
<span><span class="va">pima.nObs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">pima</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<p>For
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>532</mn></mrow><annotation encoding="application/x-tex">n=532</annotation></semantics></math>
women of Pima Indian heritage, seven possible predictors for the
presence of diabetes are recorded. We would like to investigate with a
binary regression, which of them are relevant, and what form the
statistical association has – is it a linear effect, or rather a
nonlinear effect? Here we will model possible nonlinear effects with the
fractional polynomials.</p>
<p>First, we need to decide on the prior distributions to use. We are
going to use the generalised
hyper-<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
priors for GLMs <span class="citation">(Sabanés Bové and Held
2011)</span>. They are automatic and are supposed to yield reasonable
results. We only need to specify which hyper-prior to put on the factor
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>.
One possible choice is the Zellner-Siow hyper-prior which says
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>∼</mo><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">G</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mi>/</mi><mn>2</mn><mo>,</mo><mi>n</mi><mi>/</mi><mn>2</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">g \sim \mathrm{IG}(1/2, n/2)</annotation></semantics></math>:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">glmBfp</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## define the prior distributions for g which we are going to use:</span></span>
<span><span class="va">prior</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/InvGammaGPrior.html">InvGammaGPrior</a></span><span class="op">(</span>a<span class="op">=</span><span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, </span>
<span>                        b<span class="op">=</span><span class="va">pima.nObs</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Warning in validityMethod(as(object, superClass)): density must be proper and</span></span>
<span><span class="co">## normalized: (numerical) integral is 1.00000013575921</span></span></code></pre>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## (the warning can be ignored)</span></span></code></pre></div>
<p>This corresponds to the F1 prior in <span class="citation">Sabanés
Bové and Held (2011)</span>.</p>
<p>Another possible choice is the
hyper-<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mi>/</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">g/n</annotation></semantics></math>
prior. For this there is no special constructor function, instead you
can directly specify the log prior density, as follows:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## You may also use the hyper-g/n prior:</span></span>
<span><span class="va">prior.f2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/CustomGPrior.html">CustomGPrior</a></span><span class="op">(</span>logDens<span class="op">=</span><span class="kw">function</span><span class="op">(</span><span class="va">g</span><span class="op">)</span> </span>
<span>                         <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">pima.nObs</span><span class="op">)</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="va">g</span> <span class="op">/</span> <span class="va">pima.nObs</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="stochastic-model-search">Stochastic model search<a class="anchor" aria-label="anchor" href="#stochastic-model-search"></a>
</h2>
<p>Next, we will do a stochastic search on the (very large) model space
to find “good” models. Here we have to decide on the model prior, and in
this example we use the <code>sparse</code> type which was also used in
the paper. We use a <code>chainlength</code> of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>100</mn><annotation encoding="application/x-tex">100</annotation></semantics></math>,
which is very small but enough for illustration purposes (usually one
should use at least
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn><mspace width="0.167em"></mspace><mn>000</mn></mrow><annotation encoding="application/x-tex">10\,000</annotation></semantics></math>
as a rule of thumb), and save all models (in general
<code>nModels</code> is the number of models which are saved from all
visited models). Finally, we decide that we do not want to use OpenMP
acceleration (this would parallelise loops over all observations on all
cores of your processor) and that we want to do higher order correction
for the Laplace approximations. In order to be able to reproduce the
analysis, it is advisable to set a seed for the random number generator
before starting the stochastic search.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">102</span><span class="op">)</span></span>
<span><span class="va">time.pima</span> <span class="op">&lt;-</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/system.time.html" class="external-link">system.time</a></span><span class="op">(</span><span class="va">models.pima</span> <span class="op">&lt;-</span></span>
<span>                <span class="fu"><a href="../reference/glmBayesMfp.html">glmBayesMfp</a></span><span class="op">(</span><span class="va">type</span> <span class="op">~</span> </span>
<span>                            <span class="fu"><a href="../reference/formula.html">bfp</a></span><span class="op">(</span><span class="va">npreg</span><span class="op">)</span> <span class="op">+</span> </span>
<span>                            <span class="fu"><a href="../reference/formula.html">bfp</a></span><span class="op">(</span><span class="va">glu</span><span class="op">)</span> <span class="op">+</span> </span>
<span>                            <span class="fu"><a href="../reference/formula.html">bfp</a></span><span class="op">(</span><span class="va">bp</span><span class="op">)</span> <span class="op">+</span></span>
<span>                            <span class="fu"><a href="../reference/formula.html">bfp</a></span><span class="op">(</span><span class="va">skin</span><span class="op">)</span> <span class="op">+</span> </span>
<span>                            <span class="fu"><a href="../reference/formula.html">bfp</a></span><span class="op">(</span><span class="va">bmi</span><span class="op">)</span> <span class="op">+</span> </span>
<span>                            <span class="fu"><a href="../reference/formula.html">bfp</a></span><span class="op">(</span><span class="va">ped</span><span class="op">)</span> <span class="op">+</span> </span>
<span>                            <span class="fu"><a href="../reference/formula.html">bfp</a></span><span class="op">(</span><span class="va">age</span><span class="op">)</span>,</span>
<span>                            data<span class="op">=</span><span class="va">pima</span>,</span>
<span>                            family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">binomial</a></span><span class="op">(</span><span class="st">"logit"</span><span class="op">)</span>,</span>
<span>                            priorSpecs<span class="op">=</span></span>
<span>                            <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>gPrior<span class="op">=</span><span class="va">prior</span>,</span>
<span>                                 modelPrior<span class="op">=</span><span class="st">"sparse"</span><span class="op">)</span>,</span>
<span>                            nModels<span class="op">=</span><span class="fl">1e3L</span>,</span>
<span>                            chainlength<span class="op">=</span><span class="fl">1e1L</span>,</span>
<span>                            method<span class="op">=</span><span class="st">"sampling"</span>,</span>
<span>                            useOpenMP<span class="op">=</span><span class="cn">FALSE</span>,</span>
<span>                            higherOrderCorrection<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>  </span></code></pre></div>
<pre><code><span><span class="co">## Starting sampler...</span></span>
<span><span class="co">## 0%______________________________________________________________________________________________100%</span></span>
<span><span class="co">## ----------</span></span>
<span><span class="co">## Number of non-identifiable model proposals:     0</span></span>
<span><span class="co">## Number of total cached models:                  9</span></span>
<span><span class="co">## Number of returned models:                      9</span></span></code></pre>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">time.pima</span></span></code></pre></div>
<pre><code><span><span class="co">##    user  system elapsed </span></span>
<span><span class="co">##   0.132   0.003   0.135</span></span></code></pre>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">models.pima</span>, <span class="st">"numVisited"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 9</span></span></code></pre>
<p>We see that the search took
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0</mn><annotation encoding="application/x-tex">0</annotation></semantics></math>~seconds,
and 9 models were found. Now, if we want to have a table of the found
models, with their posterior probability, the log marginal likelihood,
the log prior probability, and the powers for every covariate the and
the number of times that the sampler encountered that model:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">table.pima</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html" class="external-link">as.data.frame</a></span><span class="op">(</span><span class="va">models.pima</span><span class="op">)</span></span>
<span><span class="va">table.pima</span></span></code></pre></div>
<pre><code><span><span class="co">##      posterior logMargLik   logPrior age bmi bp glu npreg ped skin</span></span>
<span><span class="co">## 1 5.752526e-01  -265.8779 -11.849169              1           -0.5</span></span>
<span><span class="co">## 2 4.036782e-01  -266.2321 -11.849169              2           -0.5</span></span>
<span><span class="co">## 3 7.971175e-03  -270.1569 -11.849169              2              3</span></span>
<span><span class="co">## 4 6.638447e-03  -268.2604 -13.928611          0   2           -0.5</span></span>
<span><span class="co">## 5 6.134410e-03  -272.4983  -9.769728              2               </span></span>
<span><span class="co">## 6 3.250886e-04  -273.3564 -11.849169          3   2               </span></span>
<span><span class="co">## 7 2.089908e-20  -310.6396 -11.849169   2                      -0.5</span></span>
<span><span class="co">## 8 2.131992e-23  -317.5274 -11.849169                    2        3</span></span>
<span><span class="co">## 9 2.726801e-31  -339.8609  -7.690286</span></span></code></pre>
<p>Note that while <code>frequency</code> refers to the frequency of the
models in the sampling chain, thus providing a Monte Carlo estimate of
the posterior model probabilities, <code>posterior</code> refers to the
renormalised posterior model probabilities. The latter has the advantage
that ratios of posterior probabilities between any two models are exact,
while the former is unbiased (but obviously has larger variance).</p>
</div>
<div class="section level2">
<h2 id="inclusion-probabilities">Inclusion probabilities<a class="anchor" aria-label="anchor" href="#inclusion-probabilities"></a>
</h2>
<p>The estimated marginal inclusion probabilities for all covariates are
also saved:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">models.pima</span>, <span class="st">"inclusionProbs"</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   age   bmi    bp   glu npreg   ped  skin </span></span>
<span><span class="co">##  0.00  0.00  0.01  1.00  0.00  0.00  0.99</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="sampling-model-parameters">Sampling model parameters<a class="anchor" aria-label="anchor" href="#sampling-model-parameters"></a>
</h2>
<p>If we now want to look at the estimated covariate effects in the
estimated MAP model which has the configuration given in the last seven
columns of <code>table.pima</code>, then we first need to generate
parameter samples from that model:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## MCMC settings</span></span>
<span><span class="va">mcmcOptions</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/McmcOptions.html">McmcOptions</a></span><span class="op">(</span>iterations<span class="op">=</span><span class="fl">1e4L</span>,</span>
<span>                           burnin<span class="op">=</span><span class="fl">1e3L</span>,</span>
<span>                           step<span class="op">=</span><span class="fl">2L</span><span class="op">)</span></span>
<span></span>
<span><span class="co">## get samples from the MAP model</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">634</span><span class="op">)</span></span>
<span><span class="va">mapSamples</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/sampleGlm.html">sampleGlm</a></span><span class="op">(</span><span class="va">models.pima</span><span class="op">[</span><span class="fl">1L</span><span class="op">]</span>, </span>
<span>                        mcmc<span class="op">=</span><span class="va">mcmcOptions</span>,</span>
<span>                        useOpenMP<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">## Taking the linear approximation method</span></span>
<span><span class="co">## 0%______________________________________________________________________________________________100%</span></span>
<span><span class="co">## ----------------------------------------------------------------------------------------------------</span></span>
<span><span class="co">## Finished MCMC simulation with acceptance ratio 0.868</span></span></code></pre>
<p>With the function <code>McmcOptions</code>, we have defined an S4
object of MCMC settings, comprising the number of iterations, the length
of the burn-in, the thinning step (here save every second iteration),
here the acceptance rate was
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0.87</mn><annotation encoding="application/x-tex">0.87</annotation></semantics></math>).
Note that you can also get predictive samples for new data points via
the <code>newdata</code> option of <code>sampleGlm</code>. The result
<code>mapSamples</code> has the following structure:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">mapSamples</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 5</span></span>
<span><span class="co">##  $ tbf            : logi FALSE</span></span>
<span><span class="co">##  $ acceptanceRatio: num 0.868</span></span>
<span><span class="co">##  $ logMargLik     :List of 5</span></span>
<span><span class="co">##   ..$ estimate                      : Named num -266</span></span>
<span><span class="co">##   .. ..- attr(*, "names")= chr "numeratorTerms"</span></span>
<span><span class="co">##   ..$ standardError                 : num [1, 1] 0.00237</span></span>
<span><span class="co">##   ..$ numeratorTerms                : num [1:4500] 0.542 0.657 0.664 0.619 0.559 ...</span></span>
<span><span class="co">##   ..$ denominatorTerms              : num [1:4500] 1 1 0.989 1 1 ...</span></span>
<span><span class="co">##   ..$ highDensityPointLogUnPosterior: num -266</span></span>
<span><span class="co">##  $ coefficients   : num [1:3, 1:4500] -0.932 4.211 -5.46 -0.827 3.745 ...</span></span>
<span><span class="co">##   ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">##   .. ..$ : chr [1:3] "(Intercept)" "glu^1" "skin^-0.5"</span></span>
<span><span class="co">##   .. ..$ : NULL</span></span>
<span><span class="co">##  $ samples        :Formal class 'GlmBayesMfpSamples' [package "glmBfp"] with 8 slots</span></span>
<span><span class="co">##   .. ..@ fitted       : num [1:532, 1:4500] -2.29 2.55 -2.11 1.66 -1.6 ...</span></span>
<span><span class="co">##   .. .. ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">##   .. .. .. ..$ : chr [1:532] "1" "2" "3" "4" ...</span></span>
<span><span class="co">##   .. .. .. ..$ : NULL</span></span>
<span><span class="co">##   .. ..@ predictions  : logi[0 , 0 ] </span></span>
<span><span class="co">##   .. ..@ fixCoefs     :List of 1</span></span>
<span><span class="co">##   .. .. ..$ (Intercept): num [1, 1:4500] -0.932 -0.827 -0.932 -0.936 -1.073 ...</span></span>
<span><span class="co">##   .. .. .. ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">##   .. .. .. .. ..$ : chr "(Intercept)"</span></span>
<span><span class="co">##   .. .. .. .. ..$ : NULL</span></span>
<span><span class="co">##   .. ..@ z            : num [1:4500] 5.32 5.44 7.19 5.08 5.57 ...</span></span>
<span><span class="co">##   .. ..@ bfpCurves    :List of 2</span></span>
<span><span class="co">##   .. .. ..$ glu : num [1:327, 1:4500] -3.05 -3.02 -3.01 -2.99 -2.96 ...</span></span>
<span><span class="co">##   .. .. .. ..- attr(*, "scaledGrid")= num [1:327, 1] 0.56 0.567 0.57 0.574 0.581 ...</span></span>
<span><span class="co">##   .. .. .. .. ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">##   .. .. .. .. .. ..$ : NULL</span></span>
<span><span class="co">##   .. .. .. .. .. ..$ : chr "glu"</span></span>
<span><span class="co">##   .. .. .. ..- attr(*, "whereObsVals")= int [1:532] 62 318 40 251 113 88 55 313 197 163 ...</span></span>
<span><span class="co">##   .. .. ..$ skin: num [1:251, 1:4500] -3.67 -3.47 -3.28 -3.25 -3.11 ...</span></span>
<span><span class="co">##   .. .. .. ..- attr(*, "scaledGrid")= num [1:251, 1] 0.7 0.746 0.791 0.8 0.837 ...</span></span>
<span><span class="co">##   .. .. .. .. ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">##   .. .. .. .. .. ..$ : NULL</span></span>
<span><span class="co">##   .. .. .. .. .. ..$ : chr "skin"</span></span>
<span><span class="co">##   .. .. .. ..- attr(*, "whereObsVals")= int [1:532] 67 83 108 115 57 63 76 28 25 95 ...</span></span>
<span><span class="co">##   .. ..@ ucCoefs      : list()</span></span>
<span><span class="co">##   .. ..@ shiftScaleMax: num [1:7, 1:4] 0 0 0 0 1 0 0 10 100 100 ...</span></span>
<span><span class="co">##   .. .. ..- attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">##   .. .. .. ..$ : chr [1:7] "age" "bmi" "bp" "glu" ...</span></span>
<span><span class="co">##   .. .. .. ..$ : chr [1:4] "shift" "scale" "maxDegree" "cardPowerset"</span></span>
<span><span class="co">##   .. ..@ nSamples     : int 4500</span></span></code></pre>
<p>It is a list with the <code>acceptanceRatio</code> of the
Metropolis-Hastings proposals, an MCMC estimate for the log marginal
likelihood including an associated standard error
(<code>logMargLik</code>), the <code>coefficients</code> samples of the
model, and an S4 object <code>samples</code>. This S4 object includes
the <code>fitted</code> samples on the linear predictor scale (in our
case on the log Odds Ratio scale), possibly <code>predictions</code>
samples, samples of the intercept (<code>fixed</code>), samples of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>g</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">z=\log(g)</annotation></semantics></math>,
samples of the fractional polynomial curves (<code>bfpCurves</code>),
coefficients of uncertain but fixed form covariates
(<code>ucCoefs</code>), the shifts and scales applied to the original
covariates (<code>shiftScaleMax</code>) and the number of samples
(<code>nSamples</code>). You can read more details on the results on the
help page by typing <code><a href="../reference/GlmBayesMfpSamples-class.html">?"GlmBayesMfpSamples-class"</a></code> in
<code>R</code>.</p>
<p>If we wanted to get posterior fitted values on the probability scale,
we can use the following code:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mapFit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowMeans</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Logistic.html" class="external-link">plogis</a></span><span class="op">(</span><span class="va">mapSamples</span><span class="op">$</span><span class="va">samples</span><span class="op">@</span><span class="va">fitted</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">mapFit</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##         1         2         3         4         5         6 </span></span>
<span><span class="co">## 0.1017081 0.8967206 0.1096366 0.7864968 0.1794264 0.1412198</span></span></code></pre>
<p>We can also analyse the MCMC output in greater detail by applying the
functions in the <code>coda</code> package:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">coda</span><span class="op">)</span></span>
<span></span>
<span><span class="va">coefMcmc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/coda/man/mcmc.html" class="external-link">mcmc</a></span><span class="op">(</span>data<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">mapSamples</span><span class="op">$</span><span class="va">coefficients</span><span class="op">)</span>,</span>
<span>                 start<span class="op">=</span><span class="va">mcmcOptions</span><span class="op">@</span><span class="va">burnin</span> <span class="op">+</span> <span class="fl">1</span>,</span>
<span>                 thin<span class="op">=</span><span class="va">mcmcOptions</span><span class="op">@</span><span class="va">step</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">coefMcmc</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##  'mcmc' num [1:4500, 1:3] -0.932 -0.827 -0.932 -0.936 -1.073 ...</span></span>
<span><span class="co">##  - attr(*, "dimnames")=List of 2</span></span>
<span><span class="co">##   ..$ : NULL</span></span>
<span><span class="co">##   ..$ : chr [1:3] "(Intercept)" "glu^1" "skin^-0.5"</span></span>
<span><span class="co">##  - attr(*, "mcpar")= num [1:3] 1001 9999 2</span></span></code></pre>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## standard summary table for the coefficients:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">coefMcmc</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">## Iterations = 1001:9999</span></span>
<span><span class="co">## Thinning interval = 2 </span></span>
<span><span class="co">## Number of chains = 1 </span></span>
<span><span class="co">## Sample size per chain = 4500 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## 1. Empirical mean and standard deviation for each variable,</span></span>
<span><span class="co">##    plus standard error of the mean:</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##                Mean     SD Naive SE Time-series SE</span></span>
<span><span class="co">## (Intercept) -0.9298 0.1144 0.001705       0.001812</span></span>
<span><span class="co">## glu^1        3.8503 0.3963 0.005907       0.006548</span></span>
<span><span class="co">## skin^-0.5   -4.0626 1.0093 0.015046       0.017079</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## 2. Quantiles for each variable:</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##               2.5%    25%    50%     75%   97.5%</span></span>
<span><span class="co">## (Intercept) -1.158 -1.008 -0.929 -0.8514 -0.7113</span></span>
<span><span class="co">## glu^1        3.085  3.581  3.846  4.0998  4.6522</span></span>
<span><span class="co">## skin^-0.5   -6.053 -4.736 -4.057 -3.3781 -2.1071</span></span></code></pre>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/coda/man/autocorr.html" class="external-link">autocorr</a></span><span class="op">(</span><span class="va">coefMcmc</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## , , (Intercept)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##          (Intercept)        glu^1   skin^-0.5</span></span>
<span><span class="co">## Lag 0    1.000000000 -0.198545301  0.22364820</span></span>
<span><span class="co">## Lag 2    0.060585352 -0.021893505  0.02726208</span></span>
<span><span class="co">## Lag 10  -0.009556659  0.011005546  0.02048678</span></span>
<span><span class="co">## Lag 20  -0.008033578  0.001619819 -0.02348717</span></span>
<span><span class="co">## Lag 100  0.009020242 -0.025143099 -0.01664317</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## , , glu^1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##          (Intercept)        glu^1    skin^-0.5</span></span>
<span><span class="co">## Lag 0   -0.198545301  1.000000000  0.033350565</span></span>
<span><span class="co">## Lag 2   -0.015649028  0.102578846 -0.011644669</span></span>
<span><span class="co">## Lag 10  -0.006802564 -0.007056528 -0.009870305</span></span>
<span><span class="co">## Lag 20   0.025457688 -0.016328556 -0.004131432</span></span>
<span><span class="co">## Lag 100  0.010054085  0.004816710  0.006559926</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## , , skin^-0.5</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##         (Intercept)         glu^1     skin^-0.5</span></span>
<span><span class="co">## Lag 0    0.22364820  0.0333505649  1.0000000000</span></span>
<span><span class="co">## Lag 2    0.05308624  0.0007788738  0.0863690518</span></span>
<span><span class="co">## Lag 10   0.01053958 -0.0013760573  0.0004120856</span></span>
<span><span class="co">## Lag 20  -0.02397061  0.0008594714 -0.0206584865</span></span>
<span><span class="co">## Lag 100 -0.02560623 -0.0044481063 -0.0312199772</span></span></code></pre>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## etc.</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">coefMcmc</span><span class="op">)</span></span></code></pre></div>
<p><img src="examples_files/figure-html/unnamed-chunk-1-1.png" width="700"><img src="examples_files/figure-html/unnamed-chunk-1-2.png" width="700"><img src="examples_files/figure-html/unnamed-chunk-1-3.png" width="700"></p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## samples of z:</span></span>
<span><span class="va">zMcmc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/coda/man/mcmc.html" class="external-link">mcmc</a></span><span class="op">(</span>data<span class="op">=</span><span class="va">mapSamples</span><span class="op">$</span><span class="va">samples</span><span class="op">@</span><span class="va">z</span>,</span>
<span>              start<span class="op">=</span><span class="va">mcmcOptions</span><span class="op">@</span><span class="va">burnin</span> <span class="op">+</span> <span class="fl">1</span>,</span>
<span>              thin<span class="op">=</span><span class="va">mcmcOptions</span><span class="op">@</span><span class="va">step</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">zMcmc</span><span class="op">)</span></span></code></pre></div>
<p><img src="examples_files/figure-html/pima-coda-2-1.png" width="700"></p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## etc.</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="curve-estimates">Curve estimates<a class="anchor" aria-label="anchor" href="#curve-estimates"></a>
</h2>
<p>Now we can use the samples to plot the estimated effects of the MAP
model covariates, with the <code>plotCurveEstimate</code> function. For
example:</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plotCurveEstimate.html">plotCurveEstimate</a></span><span class="op">(</span>termName<span class="op">=</span><span class="st">"skin"</span>,</span>
<span>                  samples<span class="op">=</span><span class="va">mapSamples</span><span class="op">$</span><span class="va">samples</span><span class="op">)</span></span></code></pre></div>
<p><img src="examples_files/figure-html/pima-plot-ex-1.png" width="700"></p>
</div>
<div class="section level2">
<h2 id="model-averaging">Model averaging<a class="anchor" aria-label="anchor" href="#model-averaging"></a>
</h2>
<p>Model averaging works in principle similar to sampling from a single
model, but multiple model configurations are supplied and their
respective log posterior probabilities. For example, if we wanted to
average the top three models found, we would do the following:</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">312</span><span class="op">)</span></span>
<span><span class="va">bmaSamples</span> <span class="op">&lt;-</span> </span>
<span>    <span class="fu"><a href="../reference/sampleBma.html">sampleBma</a></span><span class="op">(</span><span class="va">models.pima</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span>,</span>
<span>              mcmc<span class="op">=</span><span class="va">mcmcOptions</span>,</span>
<span>              useOpenMP<span class="op">=</span><span class="cn">FALSE</span>,</span>
<span>              nMargLikSamples<span class="op">=</span><span class="fl">1000</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">## Starting sampling ...</span></span>
<span><span class="co">## Now at model  1 ...</span></span>
<span><span class="co">## Taking the linear approximation method</span></span>
<span><span class="co">## 0%______________________________________________________________________________________________100%</span></span>
<span><span class="co">## ----------------------------------------------------------------------------------------------------</span></span>
<span><span class="co">## Finished MCMC simulation with acceptance ratio 0.875 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Now at model  2 ...</span></span>
<span><span class="co">## Taking the linear approximation method</span></span>
<span><span class="co">## 0%______________________________________________________________________________________________100%</span></span>
<span><span class="co">## -----------------------------------------------------------------------------------------------------</span></span>
<span><span class="co">## Finished MCMC simulation with acceptance ratio 0.864 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Now at model  3 ...</span></span>
<span><span class="co">## Taking the linear approximation method</span></span>
<span><span class="co">## 0%______________________________________________________________________________________________100%</span></span>
<span><span class="co">## ----------------------------------------------------------------------------------------------------</span></span>
<span><span class="co">## Finished MCMC simulation with acceptance ratio 0.886</span></span></code></pre>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## look at the list element names:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">bmaSamples</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] "modelData" "samples"</span></span></code></pre>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## now we can see how close the MCMC estimates ("margLikEstimate")</span></span>
<span><span class="co">## are to the ILA estimates ("logMargLik") of the log marginal likelihood:</span></span>
<span><span class="va">bmaSamples</span><span class="op">$</span><span class="va">modelData</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"logMargLik"</span>, <span class="st">"margLikEstimate"</span><span class="op">)</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##   logMargLik margLikEstimate</span></span>
<span><span class="co">## 1  -265.8779       -265.8792</span></span>
<span><span class="co">## 2  -266.2321       -266.2333</span></span>
<span><span class="co">## 3  -270.1569       -270.1514</span></span></code></pre>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## the "samples" list is again of class "GlmBayesMfpSamples":</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/class.html" class="external-link">class</a></span><span class="op">(</span><span class="va">bmaSamples</span><span class="op">$</span><span class="va">samples</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] "GlmBayesMfpSamples"</span></span>
<span><span class="co">## attr(,"package")</span></span>
<span><span class="co">## [1] "glmBfp"</span></span></code></pre>
<p>Then internally, first the models are sampled, and for each sampled
model so many samples are drawn as determined by the model frequency in
the model average sample. The result is a list with two elements:
<code>modelData</code> is similar to the <code>table.pima</code>, and
contains in addition to that the BMA probability and frequency in the
sample, the MCMC acceptance ratios (which should be high). On the second
element <code>samples</code>, which is again of class
<code>GlmBayesMfpSamples</code>, the above presented functions can again
be applied (e.g. <code>plotCurveEstimate</code>).</p>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-sabanesbove.held2011" class="csl-entry">
Sabanés Bové, Daniel, and Leonhard Held. 2011.
<span>“<span>H</span>yper-<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>g</mi><annotation encoding="application/x-tex">g</annotation></semantics></math>
Priors for Generalized Linear Models.”</span> <em>Bayesian Analysis</em>
6 (3): 387–410. <a href="https://doi.org/10.1214/11-BA615" class="external-link">https://doi.org/10.1214/11-BA615</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Isaac Gravestock, Daniel Sabanes Bove.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
